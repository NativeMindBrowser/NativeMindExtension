{
  "chat": {
    "messages": {
      "thought_for_seconds": "R√©flexion pendant {second} seconde | R√©flexion pendant {second} secondes",
      "thinking": "R√©flexion en cours...",
      "reading": "Lecture en cours",
      "search_locally": "Recherche locale dans le navigateur..."
    },
    "quick_actions": {
      "title": "Actions rapides"
    },
    "input": {
      "placeholder": {
        "ask_anything": "Posez n'importe quelle question...",
        "ask_follow_up": "Posez une question compl√©mentaire..."
      },
      "tab_selector": {
        "all_tabs": "Tous les onglets ouverts"
      }
    },
    "prompt": {
      "highlight_key_insights": {
        "title": "Mettre en √©vidence les informations cl√©s"
      },
      "search_more": {
        "title": "Rechercher plus de contenu comme celui-ci"
      },
      "summarize_page_content": {
        "title": "R√©sumer la page"
      }
    }
  },
  "onboarding": {
    "banner": {
      "description": "Priv√© et s√©curis√©, avec des fonctionnalit√©s puissantes qui fonctionnent enti√®rement sur votre appareil.",
      "title": "IA sur appareil, con√ßue sp√©cialement pour vous"
    },
    "guide": {
      "already_installed": "Ollama est d√©j√† install√© et en cours d'ex√©cution ?",
      "features": {
        "1": "Ex√©cutez des mod√®les avanc√©s comme DeepSeek, Qwen, Llama",
        "2": "Personnalisez et changez de mod√®les avec un contr√¥le total",
        "3": "Vos donn√©es restent priv√©es, sur votre appareil"
      },
      "follow_our_tutorial": "Suivez notre guide d'installation",
      "get_ollama": "Obtenir Ollama",
      "install_desc": "Installez Ollama pour configurer votre IA locale.",
      "need_help": "Besoin d'aide ?",
      "ollama_desc": "Lib√©rez toute la puissance de l'IA locale avec Ollama.",
      "setup": "Configuration",
      "step1": "√âTAPE 1"
    },
    "webllm_tutorial": {
      "desc": "Utilisez un mod√®le l√©ger (Qwen 0.6b) directement dans votre navigateur - sans configuration, sans attente.",
      "not_support_webllm": "WebLLM n'est pas pris en charge sur votre appareil",
      "start_with_webllm": "Commencer avec le mod√®le Web",
      "title": "Pas pr√™t √† installer ? \nEssayez-le instantan√©ment."
    },
    "welcome_msg": {
      "title": "üëã Bienvenue sur **NativeMind**",
      "body": "NativeMind est une extension de navigateur IA qui privil√©gie la confidentialit√© et vous aide √† discuter, rechercher et traduire - le tout aliment√© par des mod√®les de langage fonctionnant sur votre appareil.\n\n\nVoici ce que vous pouvez faire avec NativeMind :\n\n\n\n- Discuter √† travers plusieurs onglets pour suivre diff√©rentes pages.\n\n- Rechercher sur le Web directement dans le chat pour plus de contexte.\n\n- Cliquer avec le bouton droit pour traduire instantan√©ment n'importe quelle partie de la page.\n\n- Changer ou t√©l√©charger des mod√®les √† tout moment dans les Param√®tres.\n\n\nVous pouvez commencer par essayer les actions rapides ci-dessous."
    }
  },
  "settings": {
    "advanced": {
      "title": "Avanc√©"
    },
    "choose_model": "Choisir le mod√®le",
    "download": "T√©l√©charger",
    "feedback": {
      "contact_msg": "üìß Des questions ou des commentaires ? \nRejoignez notre {discord} ou envoyez-nous un e-mail √† {email}.",
      "join_waitlist": "üíº Vous souhaitez l'utiliser au travail ? \n{join_waitlist_link} pour les mises √† jour professionnelles.",
      "join_waitlist_link": "Rejoignez la liste d'attente",
      "discord": "Discord"
    },
    "get_ollama": "Obtenir Ollama",
    "models": {
      "title": "Mod√®le actif"
    },
    "ollama": {
      "already_installed": "Ollama est d√©j√† install√© et en cours d'ex√©cution ?",
      "connected": "Connect√©",
      "connection_error": "Erreur de connexion",
      "downloadable_model": "Mod√®les t√©l√©chargeables",
      "follow_guide": "Suivez notre guide d'installation",
      "learn_more_about_models": "En savoir plus sur les mod√®les",
      "need_help": "Besoin d'aide ?",
      "re_scan": "Scanner √† nouveau",
      "server_address": "Adresse du serveur",
      "setup": "Configuration",
      "unconnected": "Non connect√©"
    },
    "prompts": {
      "chat_system_prompt": "Instruction syst√®me de chat",
      "title": "Instructions",
      "translation_system_prompt": "Instruction syst√®me de traduction"
    },
    "provider": {
      "title": "Fournisseur de mod√®les"
    },
    "provider_model": {
      "title": "Fournisseur"
    },
    "quick_actions": {
      "description": "Configurez des actions rapides pour ex√©cuter vos instructions pr√©f√©r√©es plus rapidement - depuis le nouveau chat ou le menu contextuel.",
      "edit": {
        "cancel": "Annuler",
        "prompt": "Instruction",
        "reset": "R√©initialiser",
        "save": "Enregistrer",
        "show_in_context_menu": "Afficher dans le menu contextuel",
        "title": "Titre"
      },
      "title": "Personnaliser les actions rapides"
    },
    "test": "Test",
    "translation": {
      "title": "Langue de traduction"
    },
    "webllm-desc": "Utilisation de WebLLM pour un essai rapide. \nPour une prise en charge compl√®te des mod√®les et de meilleures performances, veuillez installer Ollama.",
    "general": {
      "system_language": "Langue du syst√®me",
      "title": "G√©n√©ral"
    },
    "title": "Param√®tres"
  },
  "context_menu": {
    "quick_actions": {
      "title": "Actions rapides"
    },
    "translation": {
      "show_original": "Afficher l'original",
      "translate_page_into": "Traduire cette page en {language}"
    }
  },
  "errors": {
    "model_not_found": "Oups ! Quelque chose s'est mal pass√©. Veuillez v√©rifier votre connexion Ollama dans les param√®tres et r√©essayer.",
    "model_request_error": "Oups ! Quelque chose s'est mal pass√©. Veuillez v√©rifier votre connexion Ollama dans les param√®tres et r√©essayer.",
    "timeout_error": "Op√©ration expir√©e : {message}",
    "unknown_error": "Une erreur inattendue s'est produite : {message}",
    "model_request_timeout": "D√©lai de requ√™te expir√©. Veuillez v√©rifier votre connexion Ollama ou envisager de d√©marrer une nouvelle session, car les contextes longs peuvent affecter les temps de r√©ponse."
  }
}
