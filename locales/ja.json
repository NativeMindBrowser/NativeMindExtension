{
  "chat": {
    "messages": {
      "thought_for_seconds": "{second}秒間考えています | {second}秒間考えています",
      "thinking": "考え中...",
      "reading": "読み込み中",
      "search_locally": "ブラウザ内で検索中..."
    },
    "quick_actions": {
      "title": "クイックアクション"
    },
    "input": {
      "placeholder": {
        "ask_anything": "何でも質問してください...",
        "ask_follow_up": "続けて質問してください..."
      },
      "tab_selector": {
        "all_tabs": "すべての開いているタブ"
      }
    },
    "prompt": {
      "highlight_key_insights": {
        "title": "重要な洞察を強調する"
      },
      "search_more": {
        "title": "このようなコンテンツをもっと検索する"
      },
      "summarize_page_content": {
        "title": "ページを要約する"
      }
    }
  },
  "onboarding": {
    "banner": {
      "description": "プライバシーと安全性を確保しながら、デバイス内で完全に動作する強力な機能を体験できます。",
      "title": "あなたのために開発されたオンデバイスAI"
    },
    "guide": {
      "already_installed": "すでにOllamaをインストールして実行していますか？",
      "features": {
        "1": "DeepSeek、Qwen、Llamaなどの高度なモデルを実行できます",
        "2": "完全な制御でモデルをカスタマイズし切り替えられます",
        "3": "あなたのデータはデバイス上でプライベートに保たれます"
      },
      "follow_our_tutorial": "インストールガイドを確認する",
      "get_ollama": "Ollamaを入手する",
      "install_desc": "Ollamaをインストールして、ローカルAI環境を構築しましょう。",
      "need_help": "お困りですか？",
      "ollama_desc": "Ollamaで完全なローカルAIのパワーを活用しましょう。",
      "setup": "セットアップ",
      "step1": "ステップ 1"
    },
    "webllm_tutorial": {
      "desc": "ブラウザで直接軽量モデル（Qwen 0.6b）を使用できます。セットアップ不要、待ち時間なし。",
      "not_support_webllm": "WebLLMはお使いのデバイスではサポートされていません",
      "start_with_webllm": "Webモデルで始める",
      "title": "インストールの準備ができていませんか？すぐに試してみましょう。"
    },
    "welcome_msg": {
      "title": "👋 **NativeMind** へようこそ",
      "body": "NativeMindは、プライバシー重視のAIブラウザ拡張機能で、オンデバイス言語モデルを活用したチャット、検索、翻訳機能を提供します。\n\nNativeMindでできることは次のとおりです：\n\n- 複数のタブでチャットし、異なるページを管理できます。\n- チャット内で直接ウェブ検索を行い、より多くのコンテキストを得られます。\n- 右クリックでページの任意の部分を即座に翻訳できます。\n- 設定からいつでもモデルの切り替えやダウンロードが可能です。\n\n下記のクイックアクションを試してみましょう。"
    }
  },
  "settings": {
    "advanced": {
      "title": "詳細設定"
    },
    "choose_model": "モデルを選択",
    "download": "ダウンロード",
    "feedback": {
      "contact_msg": "📧ご質問やフィードバックがありますか？{discord}に参加するか、{email}までメールでお問い合わせください。",
      "join_waitlist": "💼職場でご利用希望の方は、エンタープライズ版の最新情報を受け取るために{join_waitlist_link}してください。",
      "join_waitlist_link": "ウェイトリストに登録",
      "discord": "Discord"
    },
    "get_ollama": "Ollamaを入手",
    "models": {
      "title": "アクティブなモデル"
    },
    "ollama": {
      "already_installed": "Ollamaをすでにインストールして実行していますか？",
      "connected": "接続済み",
      "connection_error": "接続エラー",
      "downloadable_model": "ダウンロード可能なモデル",
      "follow_guide": "インストールガイドを確認する",
      "learn_more_about_models": "モデルについて詳しく知る",
      "need_help": "お困りですか？",
      "re_scan": "再スキャン",
      "server_address": "サーバーアドレス",
      "setup": "セットアップ",
      "unconnected": "未接続"
    },
    "prompts": {
      "chat_system_prompt": "チャットシステムプロンプト",
      "title": "プロンプト",
      "translation_system_prompt": "翻訳システムプロンプト"
    },
    "provider": {
      "title": "モデルプロバイダー"
    },
    "provider_model": {
      "title": "プロバイダー＆モデル"
    },
    "quick_actions": {
      "description": "新規チャットや右クリックメニューから、お気に入りのプロンプトをより速く実行できるようクイックアクションを設定します。",
      "edit": {
        "cancel": "キャンセル",
        "prompt": "プロンプト",
        "reset": "リセット",
        "save": "保存",
        "show_in_context_menu": "右クリックメニューに表示する",
        "title": "タイトル"
      },
      "title": "クイックアクションのカスタマイズ"
    },
    "test": "テスト",
    "translation": {
      "title": "翻訳言語"
    },
    "webllm-desc": "WebLLMを使用して素早く試すことができます。完全なモデル対応と高いパフォーマンスを得るには、Ollamaをインストールしてください。",
    "general": {
      "system_language": "システム言語",
      "title": "一般"
    },
    "title": "設定"
  },
  "context_menu": {
    "quick_actions": {
      "title": "クイックアクション"
    },
    "translation": {
      "show_original": "原文を表示",
      "translate_page_into": "このページを{language}に翻訳"
    }
  },
  "errors": {
    "model_not_found": "おっと！何か問題が発生しました。設定でOllama接続を確認し、再度お試しください。",
    "timeout_error": "操作がタイムアウトしました：{message}",
    "unknown_error": "予期しないエラーが発生しました：{message}",
    "model_request_error": "おっと！何か問題が発生しました。設定でOllama接続を確認し、再度お試しください。",
    "model_request_timeout": "リクエストがタイムアウトしました。Ollama接続を確認するか、長いコンテキストが応答時間に影響を与える可能性があるため、新しいセッションの開始をご検討ください。"
  }
}
