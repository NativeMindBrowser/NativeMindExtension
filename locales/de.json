{
  "chat": {
    "messages": {
      "thinking": "Denken...",
      "reading": "Lekt√ºre",
      "search_locally": "Lokal im Browser suchen‚Ä¶",
      "thought_for_seconds": "Gedanke f√ºr {second} Sekunde | Gedanke f√ºr {second} Sekunden"
    },
    "quick_actions": {
      "title": "Schnelle Aktionen"
    },
    "input": {
      "placeholder": {
        "ask_anything": "Fragen Sie alles ...",
        "ask_follow_up": "Fragen Sie nach Follow -up ..."
      },
      "tab_selector": {
        "all_tabs": "Alle √∂ffnen Registerkarten"
      }
    },
    "prompt": {
      "highlight_key_insights": {
        "title": "Wichtige Erkenntnisse hervorheben"
      },
      "search_more": {
        "title": "Suchen Sie nach weiteren Inhalten wie diesem"
      },
      "summarize_page_content": {
        "title": "Seite zusammenfassen"
      }
    }
  },
  "onboarding": {
    "banner": {
      "description": "Privat und sicher, mit leistungsstarken Funktionen, die vollst√§ndig in Ihrem Ger√§t ausgef√ºhrt werden.",
      "title": "KI On-Device, nur f√ºr Sie gebaut"
    },
    "guide": {
      "already_installed": "Bereits installiert und Ollama laufen?",
      "features": {
        "1": "F√ºhren Sie fortschrittliche Modelle wie Deepseek, Qwen, Lama aus",
        "2": "Passen Sie die Modelle mit voller Steuerung an und wechseln Sie sie",
        "3": "Ihre Daten bleiben privat auf Ihrem Ger√§t"
      },
      "follow_our_tutorial": "Folgen Sie unserem Installationshandbuch",
      "get_ollama": "Holen Sie sich Ollama",
      "install_desc": "Installieren Sie Ollama, um Ihre lokale KI einzurichten.",
      "need_help": "Ben√∂tigen Sie Hilfe?",
      "ollama_desc": "Mit Ollama die volle lokale KI -Macht freischalten.",
      "setup": "Aufstellen",
      "step1": "Schritt 1",
      "download_model_to_begin": "Laden Sie ein Modell herunter, um zu beginnen.",
      "select_model_to_start": "W√§hlen Sie ein Modell aus und laden Sie es herunter, um zu beginnen"
    },
    "webllm_tutorial": {
      "desc": "Verwenden Sie ein leichtes Modell (QWEN 0,6B) direkt in Ihrem Browser - kein Setup, kein Warten.",
      "not_support_webllm": "Webllm wird auf Ihrem Ger√§t nicht unterst√ºtzt",
      "start_with_webllm": "Beginnen Sie mit dem Webmodell",
      "title": "Nicht bereit zu installieren? \nVersuchen Sie es sofort."
    },
    "welcome_msg": {
      "title": "üëã Willkommen bei **NativeMind**",
      "body": "NATIVEMIND ist eine Datenschutz-AI-Browser-Erweiterung, die Ihnen hilft, zu chatten, zu suchen und zu √ºbersetzen-alles mit Sprachmodellen f√ºr das Ger√§t.\n\n\nFolgendes k√∂nnen Sie mit Nativemind machen:\n\n\n\n- Chatten Sie √ºber mehrere Registerkarten hinweg, um verschiedene Seiten im Auge zu behalten.\n\n- Durchsuchen Sie das Web direkt im Chat, um einen weiteren Kontext zu erhalten.\n\n- Klicken Sie mit der rechten Maustaste, um einen Teil der Seite sofort zu √ºbersetzen.\n\n- Modelle jederzeit in Einstellungen wechseln oder herunterladen.\n\n\nSie k√∂nnen zun√§chst die schnellen Aktionen unten ausprobieren."
    },
    "ollama_is_running": "Ollama l√§uft"
  },
  "settings": {
    "advanced": {
      "title": "Fortschrittlich"
    },
    "choose_model": "W√§hlen Sie Modell",
    "download": "Herunterladen",
    "feedback": {
      "contact_msg": "üìßQuestions oder Feedback? \nSchlie√üen Sie sich unserem {Discord} an oder senden Sie uns eine E-Mail unter {email}.",
      "join_waitlist": "üíºWant, um es bei der Arbeit zu verwenden? \n{Join_waitlist_link} f√ºr Unternehmensaktualisierungen.",
      "join_waitlist_link": "Treten Sie der Warteliste bei",
      "discord": "Zwietracht"
    },
    "get_ollama": "Holen Sie sich Ollama",
    "models": {
      "title": "Modelle",
      "discover_more": "Entdecken Sie weitere Modelle"
    },
    "ollama": {
      "already_installed": "Bereits installiert und Ollama laufen?",
      "connected": "Verbunden",
      "connection_error": "Verbindungsfehler",
      "downloadable_model": "Herunterladbares Modell",
      "follow_guide": "Folgen Sie unserem Installationshandbuch",
      "learn_more_about_models": "Erfahren Sie mehr √ºber Models",
      "need_help": "Ben√∂tigen Sie Hilfe?",
      "re_scan": "Neu scan",
      "server_address": "Serveradresse",
      "setup": "Aufstellen",
      "unconnected": "Nicht miteinander verbunden"
    },
    "prompts": {
      "chat_system_prompt": "Chat -System Eingabeaufforderung",
      "title": "Prompt",
      "translation_system_prompt": "√úbersetzungssystem Eingabeaufforderung"
    },
    "provider": {
      "title": "Verbindung"
    },
    "provider_model": {
      "title": "Ollama konfigurieren"
    },
    "quick_actions": {
      "description": "Richten Sie schnelle Aktionen ein, um Ihre bevorzugten Eingabeaufforderungen schneller auszuf√ºhren-aus dem neuen Chat oder dem Rechtsklickmen√º.",
      "edit": {
        "cancel": "Stornieren",
        "prompt": "Prompt",
        "reset": "Zur√ºcksetzen",
        "save": "Speichern",
        "show_in_context_menu": "In der rechten Maustaste anzeigen",
        "title": "Titel"
      },
      "title": "Schnelle Aktionen anpassen"
    },
    "test": "Pr√ºfen",
    "translation": {
      "title": "√úbersetzungssprache"
    },
    "webllm-desc": "Sie verwenden jetzt WebLLM: qwen3:0.6b f√ºr einen schnellen Test. F√ºr vollst√§ndige Modellunterst√ºtzung und bessere Leistung installieren Sie bitte Ollama.",
    "general": {
      "system_language": "Systemsprache",
      "title": "Allgemein"
    },
    "title": "Einstellungen",
    "model_downloader": {
      "description": "Dieses Modell muss vor der Verwendung heruntergeladen werden. Der Download kann einige Minuten dauern.",
      "downloading_model": "Lade \"{model}\" herunter",
      "download_model": "Lade \"{model}\" herunter",
      "downloading": "Ihr Modell wird heruntergeladen. Bitte warten‚Ä¶",
      "download": "Herunterladen",
      "retry": "Wiederholen",
      "unable_to_download": "Download kann nicht gestartet werden",
      "could_not_connect_ollama": "Wir konnten keine Verbindung zu Ollama herstellen. Bitte stellen Sie sicher, dass Ollama l√§uft und versuchen Sie es erneut."
    },
    "webllm_downloader": {
      "description": "Um den lokalen Modus zu verwenden, m√ºssen Sie das {model}-Modell ({size}) herunterladen. M√∂chten Sie es jetzt herunterladen?"
    }
  },
  "context_menu": {
    "quick_actions": {
      "title": "Schnelle Aktionen"
    },
    "translation": {
      "show_original": "Original zeigen",
      "translate_page_into": "√úbersetzen Sie diese Seite in {Sprache}"
    }
  },
  "errors": {
    "model_not_found": "Hoppla! \nEtwas lief schief. \nBitte √ºberpr√ºfen Sie Ihre Ollama -Verbindung in Einstellungen und versuchen Sie es erneut.",
    "model_request_error": "Hoppla! \nEtwas lief schief. \nBitte √ºberpr√ºfen Sie Ihre Ollama -Verbindung in Einstellungen und versuchen Sie es erneut.",
    "model_request_timeout": "\"Anfordern Sie eine Zeit√ºberschreitung, √ºberpr√ºfen Sie bitte Ihre Ollama -Verbindung oder in Betracht, eine neue Sitzung zu starten, da lange Kontexte die Antwortzeiten beeinflussen k√∂nnen.\"",
    "timeout_error": "Operation zeitlich ausgegeben: {message}",
    "unknown_error": "Es ist ein unerwarteter Fehler aufgetreten: {message}",
    "webllm_not_supported": "WebLLM wird auf Ihrem Ger√§t nicht unterst√ºtzt."
  },
  "common": {
    "cancel": "Abbrechen"
  },
  "ollama": {
    "sites": {
      "add_to_nativemind": "Zu NativeMind hinzuf√ºgen"
    }
  }
}
